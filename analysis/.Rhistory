# Elahi et al. 2015. Recent trends in local-scale marine
# biodiversity reflect community structure and human impacts
# Current Biology, in press June 2015
# Funnel plots for Figure S2
# Author: Robin Elahi
# Date: 150629
#################################################
# get data for analysis
source("./R/bts_dataPrep.R")
# detach dplyr
detach("package:dplyr", unload = TRUE)
library(ggplot2)
library(nlme)
library(plyr)
# plotting functions
source("./R/Standard Graphical Pars_RE.R")
source("./R/multiplotF.R")
# Random effects for LME models
source("./R/bts_lme_models.R")
# make sure the data are ordered by time within time-series (
# necessary for autocorrelation
head(richDat$year0Z)
tail(divDat$year0Z)
############################################################
############################################################
###HMM WITH ESTIMATED SLOPES
###FOR RICHNESS AND DIVERSITY
############################################################
############################################################
# richness
richDat2 <- richDat[with(richDat, order(studyName, studySub, subSiteID, year0Z)), ]
richGlobal <- lme(fixed = richLN ~ 1 +
year0Z*Scale + year0Z*Prediction +
year0Z*Trophic + year0Z*initialRichLN +
year0Z*durationZ,
data = richDat2, method = "REML",
random =  list(rand1, rand2, rand4),
correlation = corAR1())
plot(richGlobal)
# diversity
divDat2 <- divDat[with(divDat, order(studyName, studySub, subSiteID, year0Z)), ]
divDat2$PredictionOld <- droplevels(as.factor(gsub("neutral", "none", divDat2$Prediction)))
divGlobal <- lme(fixed = div ~ 1 +
year0Z*Scale + year0Z*PredictionOld +
year0Z*Trophic + year0Z*initialDiv +
year0Z*durationZ,
data = divDat2, method = "REML",
random =  list(rand1, rand2, rand4),
correlation = corAR1(), weights = varExp())
plot(divGlobal)
# residual plots
plot(richGlobal, main = "ln(S)")
plot(divGlobal, main = "H'")
#######################################################
#######################################################
#Extract the fitted slopes for each time series to use for histograms
# get fitted values for each model
richDat2$fittedRich <- fitted(richGlobal)
divDat2$fittedDiv <- fitted(divGlobal)
# use ddply to extract slope and se
slopeRich <- ddply(richDat2, .(subSiteID, Prediction), summarize,
tempN = length(richLN),
meanS = mean(richLN),
fitSlope = coefficients(lm(fittedRich ~ year0Z))[2]
)
unique(divDat2$PredictionOld)
slopeDiv <- ddply(divDat2, .(subSiteID, PredictionOld), summarize,
tempN = length(div),
meanS = mean(div),
fitSlope = coefficients(lm(fittedDiv ~ year0Z))[2]
)
#################################
#################################
# FUNNEL PLOTS
#################################
#################################
# funnel plot for richness
lab0 <- expression(paste("Absolute value [ln(S) ", yr^-1, "]"))
lab1 <- expression(paste("Change in richness [ln(S) ", yr^-1, "]"))
lab2 <- expression(paste("Change in diversity [H' ", yr^-1, "]"))
# PUB QUALITY PLOTS
axesSpecs <- theme(axis.title = element_text(size = 12), axis.text = element_text(size = 10))
no_grid <- theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank())
plotSpecs <- theme_bw() + no_grid
regression <- geom_smooth(method = "lm", se = FALSE, size = .2)
yAxis <- scale_y_continuous(limits = c(0,1))
ULClabel <- theme(plot.title = element_text(hjust = -0.07, vjust = 0.5, size = rel(1)))
slopeRich$Prediction
###
funnelRich <- ggplot(data = slopeRich,
aes(fitSlope, tempN, color = Prediction)) +
geom_point(size = 2, alpha = 0.1) +
geom_point(size = 2, alpha = 1, pch = 21) +
plotSpecs + axesSpecs +
geom_vline(xintercept = 0, color = "gray", linetype = "dashed") +
ylab("Temporal replicates") + xlab(lab1) +
scale_x_continuous(limits = c(-0.06, 0.06)) +
theme(legend.title = element_blank()) +
scale_colour_manual(values = c("red", "darkgray", "black", "blue")) +
labs(title = "C") + ULClabel +
theme(legend.position = "none")
funnelRich
levels(slopeRich$Prediction)
levels(slopeDiv$PredictionOld)
funnelDiv <- ggplot(data = slopeDiv,
aes(fitSlope, tempN, color = PredictionOld)) +
geom_point(size = 2, alpha = 0.1) +
geom_point(size = 2, alpha = 1, pch = 21) +
plotSpecs + axesSpecs +
geom_vline(xintercept = 0, color = "gray", linetype = "dashed") +
ylab("Temporal replicates") + xlab(lab2) +
scale_x_continuous(limits = c(-0.05, 0.05)) +
theme(legend.title = element_blank()) +
scale_colour_manual(breaks = c("negative", "neutral", "positive"),
values = c("red", "black", "blue")) +
labs(title = "D") + ULClabel +
theme(legend.justification = c(1, 1),
legend.position = c(0.4, 1)) +
theme(legend.position = "none")
funnelDiv
pdf("./figs/cb_FigS2.pdf", 6.9, 6.9)
multiplot(richPlot, funnelRich, divPlot, funnelDiv, cols = 2)
dev.off()
pdf("./cb_FigS2.pdf", 6.9, 6.9)
multiplot(richPlot, funnelRich, divPlot, funnelDiv, cols = 2)
dev.off()
lmeDat <- divDat
lmeDat$PredictionOld <- droplevels(as.factor(gsub("neutral", "none", lmeDat$Prediction)))
lmeDat$PredictionOld <- relevel(lmeDat$PredictionOld, ref = "none")
unique(lmeDat$PredictionOld)
############################################################
lmeDat <- richDat
# relevel prediction
lmeDat$Prediction <- relevel(lmeDat$Prediction, ref = "none")
# Set up candidate model list
Cand.mod <- list()
# final full model
Cand.mod[[1]] <- lme(fixed = richLN ~ 1 +
year0Z*Scale + year0Z*Prediction +
year0Z*Trophic + year0Z*initialRichLN +
year0Z*durationZ,
data = lmeDat, method = "ML",
random =  list(rand1, rand2, rand4),
correlation = corAR1())
summary(Cand.mod[[1]])$tTable
# remove Scale interaction
Cand.mod[[2]] <- update(Cand.mod[[1]], ~. - year0Z:Scale)
# remove Prediction interaction
Cand.mod[[3]] <- update(Cand.mod[[1]], ~. - year0Z:Prediction)
# remove Trophic interaction
Cand.mod[[4]] <- update(Cand.mod[[1]], ~. - year0Z:Trophic)
# remove initialRichLN interaction
Cand.mod[[5]] <- update(Cand.mod[[1]], ~. - year0Z:initialRichLN)
# remove duration interaction
Cand.mod[[6]] <- update(Cand.mod[[1]], ~. - year0Z:durationZ)
# year only
Cand.mod[[7]] <- lme(fixed = richLN ~ 1 +
year0Z,
data = lmeDat, method = "ML",
random =  list(rand1, rand2, rand4),
correlation = corAR1())
# null model
Cand.mod[[8]] <- lme(fixed = richLN ~ 1,
data = lmeDat, method = "ML",
random =  list(rand1, rand2, rand4),
correlation = corAR1())
#####################
# use AICc when ratio of n/K is < 40
dim(lmeDat)[1]/22 # K = 22; can use AIC
#create a vector of names to trace back models in set
mod_numbers <- paste("Cand.mod", 1:length(Cand.mod), sep=" ")
mod_text <- c("Full model", "W/O Year:Scale", "W/O Year:Driver",
"W/O Year:Trophic Level", "W/O Year:Initial S", "W/O Year:Study Duration",
"Year only", "Null model")
#generate AICc table with numbers
mod.aicctab <- aictab(cand.set= Cand.mod, modnames=mod_numbers, sort=TRUE,
second.ord=FALSE) # second.ord =TRUE means AICc is used (not AIC)
print(mod.aicctab, digits=2, LL=TRUE)
#generate AICc table with names
mod.aicctab <- aictab(cand.set= Cand.mod, modnames= mod_text, sort=TRUE,
second.ord=FALSE) # second.ord =TRUE means AICc is used (not AIC)
print(mod.aicctab, digits=2, LL=TRUE)
library(arm)
library(AICcmodavg)
mod.aicctab <- aictab(cand.set= Cand.mod, modnames=mod_numbers, sort=TRUE,
second.ord=FALSE) # second.ord =TRUE means AICc is used (not AIC)
print(mod.aicctab, digits=2, LL=TRUE)
mod.aicctab <- aictab(cand.set= Cand.mod, modnames= mod_text, sort=TRUE,
second.ord=FALSE) # second.ord =TRUE means AICc is used (not AIC)
print(mod.aicctab, digits=2, LL=TRUE)
lmeDat <- divDat
# only one neutral prediction - lme won't run - need to use old classification
lmeDat$PredictionOld <- droplevels(as.factor(gsub("neutral", "none", lmeDat$Prediction)))
# relevel prediction
lmeDat$PredictionOld <- relevel(lmeDat$PredictionOld, ref = "none")
unique(lmeDat$PredictionOld)
# Set up candidate model list
Cand.mod <- list()
# Set up candidate model list
Cand.mod <- list()
# final full model
Cand.mod[[1]] <- lme(fixed = div ~ year0Z*Scale +
year0Z*PredictionOld +
year0Z*Trophic + year0Z*initialDiv +
year0Z*durationZ,
data = lmeDat, method = "ML",
random =  list(rand1, rand2, rand4),
correlation = corAR1(), weights = varExp())
summary(Cand.mod[[1]])
# remove Scale interaction
Cand.mod[[2]] <- update(Cand.mod[[1]], ~. - year0Z:Scale)
# remove Prediction interaction
Cand.mod[[3]] <- update(Cand.mod[[1]], ~. - year0Z:PredictionOld)
# remove Trophic interaction
Cand.mod[[4]] <- update(Cand.mod[[1]], ~. - year0Z:Trophic)
# remove initialRichLN interaction
Cand.mod[[5]] <- update(Cand.mod[[1]], ~. - year0Z:initialDiv)
# remove duration interaction
Cand.mod[[6]] <- update(Cand.mod[[1]], ~. - year0Z:durationZ)
# year only
Cand.mod[[7]] <- lme(fixed = div ~ year0Z,
data = lmeDat, method = "ML",
random =  list(rand1, rand2, rand4),
correlation = corAR1(), weights = varExp())
# null model
Cand.mod[[8]] <- lme(fixed = div ~ 1,
data = lmeDat, method = "ML",
random =  list(rand1, rand2, rand4),
correlation = corAR1(), weights = varExp())
#########	#########
# use AICc when ratio of n/K is < 40
dim(lmeDat)[1]/22 # K = 20; can use AIC
#create a vector of names to trace back models in set
mod_numbers <- paste("Cand.mod", 1:length(Cand.mod), sep=" ")
mod_text <- c("Full model", "W/O Year:Scale", "W/O Year:Driver",
"W/O Year:Trophic Level", "W/O Year:Initial H'",
"W/O Year:Study Duration", "Year only", "Null model")
#generate AICc table with names
mod.aicctab <- aictab(cand.set= Cand.mod, modnames= mod_text, sort=TRUE, second.ord=FALSE) # second.ord =TRUE means AICc is used (not AIC)
print(mod.aicctab, digits=2, LL=TRUE)
source("./bts_Fig2.R")
qplot(fitSlope, data = slopeRich)
head(slopeRich)
source("./bts_Fig2.R")
qplot(fitSlope, data = slopeRich)
# select model to use for error bars
mod <- richGlobal
summary(mod)
intervals(mod)$fixed
intervals(mod, which = 'var-cov')
# get estimate of the sd of year (random)
yearSD <- intervals(mod, which = 'var-cov')$reStruct$subSiteID["sd(year0Z", "est."]
# CI is 1.96*SD
yearCI <- 1.96*yearSD
yearCI # approximate 95% CI for the random effect
df1 <- slopeRich[with(slopeRich, order(fitSlope)), ]
df1$newRow <- seq(1:dim(df1)[1])
df1$betaUpper <- df1$fitSlope + yearCI
df1$betaLower <- df1$fitSlope - yearCI
sigUpper <- dim(df1[df1$betaLower > 0, ])[1]
sigLower <- dim(df1[df1$betaUpper < 0, ])[1]
sigUpper; sigLower
sigUpper/dim(df1)[1] # 16% sig pos
sigLower/dim(df1)[1] # 3% sig neg
sigPercentage <- (sigUpper + sigLower)/dim(df1)[1]; sigPercentage
# caterpillar plot
no_grid <- theme(panel.grid.major = element_blank()) +
theme(panel.grid.minor = element_blank())
yAxis1 <- theme(axis.title.y = element_text(size = 16), axis.text.y = element_text(size = 14))
xAxis1 <- theme(axis.title.x = element_text(size = 16), axis.text.x = element_text(size = 14))
plotSpecs <- theme_bw() + yAxis1 + xAxis1 + no_grid
ggplot(df1, aes(newRow, fitSlope)) +
geom_errorbar(aes(ymin = betaLower, ymax = betaUpper),
size = 0.03, width = 0.0,
color = "black") + geom_point(size = 1) +
geom_hline(yintercept = 0, color = "darkgray", linetype = "dashed") +
plotSpecs +
xlab("Time-series") + ylab("Slope coefficient (year)")
qplot(fitSlope, data = slopeDiv)
# select model to use for error bars
mod <- divGlobal
summary(mod)
intervals(mod)$fixed
intervals(mod, which = 'var-cov')
# get estimate of the sd of year (random)
yearSD <- intervals(mod, which = 'var-cov')$reStruct$subSiteID["sd(year0Z", "est."]
# CI is 1.96*SD
yearCI <- 1.96*yearSD
yearCI # approximate 95% CI for the random effect
df1 <- slopeDiv[with(slopeDiv, order(fitSlope)), ]
df1$newRow <- seq(1:dim(df1)[1])
df1$betaUpper <- df1$fitSlope + yearCI
df1$betaLower <- df1$fitSlope - yearCI
sigUpper <- dim(df1[df1$betaLower > 0, ])[1]
sigLower <- dim(df1[df1$betaUpper < 0, ])[1]
sigUpper; sigLower
sigUpper/dim(df1)[1] # 6% sig pos
sigLower/dim(df1)[1] # 3% sig neg
sigPercentage <- (sigUpper + sigLower)/dim(df1)[1]; sigPercentage
# caterpillar plot
ggplot(df1, aes(newRow, fitSlope)) +
geom_errorbar(aes(ymin = betaLower, ymax = betaUpper),
size = 0.03, width = 0.0,
color = "black") + geom_point(size = 1) +
geom_hline(yintercept = 0, color = "darkgray", linetype = "dashed") +
plotSpecs +
xlab("Time-series") + ylab("Slope coefficient (year)")
source("./R/bts_dataPrep.R")
# detach dplyr
detach("package:dplyr", unload = TRUE)
library(nlme)
library(reshape2)
library(plyr)
# get stuff for lme models
source("./R/bts_lme_models.R")
# make sure the data are ordered by time within time-series (
# necessary for autocorrelation
head(richDat$year0Z)
tail(richDat$year0Z)
# richness
dat <- richDat
dat$Prediction <- relevel(dat$Prediction, ref = "none")
############################################################
############################################################
#Get p-value
getTrtP <- function(newDF){
model.i <- lme(fixed = richLN ~ 1 +
year0Z*Scale + year0Z*Prediction +
year0Z*Trophic + year0Z*initialRichLN +
year0Z*durationZ,
data = newDF, method = "ML",
random =  list(rand1, rand2, rand4),
correlation = corAR1())
overallP <- anova(model.i)[9,4] # overall p value
levelP <- unname(summary(model.i)$tTable[12:14, 5]) # p values for each level
pVector <- c(overallP, levelP)
return(pVector)
}
# create vector of new predictions corresponding to length of old prediction
switchFactor3 <- function(x) {
predictionOld <- unique(x)
if(predictionOld == "negative") {predictionNew <- "neutral"}
if(predictionOld == "positive") {predictionNew <- "neutral"}
if(predictionOld == "neutral")
{predictionNew <- sample(c("negative", "positive"), 1)}
predictionVector <- rep(predictionNew, length(x))
return(predictionVector)}
# vector of time series names that were classified as neutral, positive, or negative
tsNames <- unique(dat[dat$Prediction != "none", ]$subSiteID)
tsNames
tsN <- length(tsNames); tsN
changeOneF <- function(dat) {
randSample <- sample(tsNames, 1)
randChange <- dat[dat$subSiteID == randSample, ]; dim(randChange)
unique(randChange$Prediction)
switchFactor(randChange)
predictionNew <- rep(switchFactor(randChange), length(randChange$Prediction))
randChange2 <- randChange; randChange2$Prediction <- predictionNew
randKeep <- dat[dat$subSiteID != randSample, ]; dim(randKeep)
newDF <- rbind(randKeep,  randChange2)
dim(newDF)
getTrtP(newDF)
}
system.time(changeOneF(dat)) # ~ 10 seconds, most/all of which is the lme call
randSample <- sample(tsNames, 50)
randSample
tsNames <- unique(dat[dat$Prediction != "none", ]$subSiteID)
tsNames
tsN <- length(tsNames); tsN
switcharoo <- function(dat, newPredictions) {
randSample <- sample(tsNames, newPredictions)
# create subset to change
randChange <- dat[dat$subSiteID %in% randSample, ]
# create subset to keep
randKeep <- dat[!dat$subSiteID %in% randSample, ]
# get list of new predictions
predictionList <- tapply(X = randChange$Prediction,
INDEX = randChange$subSiteID, FUN = switchFactor3)
#need to change from list to a vector/data frame
predictionNew <- factor(matrix(unlist(predictionList)))
# create new changed subset of data
randChange2 <- randChange
randChange2$Prediction <- predictionNew
# create the new data frame
newDF <- rbind(randKeep,  randChange2)
# run the model and get the pValue
getTrtP(newDF)
}
switcharoo(dat, 2)
dat <- divDat
# only one neutral prediction - lme won't run - need to use old classification
dat$PredictionOld <- droplevels(as.factor(gsub("neutral", "none", dat$Prediction)))
# relevel prediction
dat$PredictionOld <- relevel(dat$PredictionOld, ref = "none")
unique(dat$PredictionOld)
setwd("~/Desktop/currentResearch/1_biodiversityChange/bts_currentBiologyMS/biodiversity time series/bts data_master/bts_analysis CurrBio3")
rm(list=ls(all=TRUE)) # removes all previous material from R's memory
# get data for analysis
source("./R/bts_dataPrep_150620.R")
# detach dplyr
detach("package:dplyr", unload = TRUE)
library(nlme)
library(reshape2)
library(plyr)
# get stuff for lme models
source("./R/bts_lme_models_150618.R")
# make sure the data are ordered by time within time-series (
# necessary for autocorrelation
head(divDat$year0Z)
tail(divDat$year0Z)
# diversity
dat <- divDat
unique(dat$PredictionOld)
unique(dat$PredictionOld)
setwd("~/Desktop/currentResearch/1_biodiversityChange/bts_currentBiologyMS/bts_gitHubRepo/analysis")
rm(list=ls(all=TRUE)) # removes all previous material from R's memory
# get data for analysis
source("./R/bts_dataPrep_150620.R")
# detach dplyr
detach("package:dplyr", unload = TRUE)
library(nlme)
library(reshape2)
library(plyr)
# Random effects for LME models
source("./R/bts_lme_models.R")
# make sure the data are ordered by time within time-series (
# necessary for autocorrelation
head(divDat$year0Z)
tail(divDat$year0Z)
# diversity
dat <- divDat
setwd("~/Desktop/currentResearch/1_biodiversityChange/bts_currentBiologyMS/bts_gitHubRepo/analysis")
source("./R/bts_dataPrep.R")
# detach dplyr
detach("package:dplyr", unload = TRUE)
library(nlme)
library(reshape2)
library(plyr)
# Random effects for LME models
source("./R/bts_lme_models.R")
# make sure the data are ordered by time within time-series (
# necessary for autocorrelation
head(divDat$year0Z)
tail(divDat$year0Z)
# diversity
dat <- divDat
unique(dat$Prediction)
with(dat, table(Prediction))
dat$PredictionOld <- droplevels(as.factor(gsub("none", "neutral", dat$Prediction)))
unique(dat$PredictionOld)
# relevel predictionOld
dat$PredictionOld <- relevel(dat$PredictionOld, ref = "neutral")
with(dat, table(Prediction))
with(dat, table(PredictionOld))
getTrtP <- function(newDF){
model.i <- lme(fixed = div ~ 1 +
year0Z*Scale + year0Z*PredictionOld +
year0Z*Trophic + year0Z*initialDiv +
year0Z*durationZ,
data = newDF, method = "ML",
random =  list(rand1, rand2, rand4),
correlation = corAR1(), weights = varExp())
overallP <- anova(model.i)[9,4] # overall p value
levelP <- unname(summary(model.i)$tTable[11:12, 5])
# p values for each level
pVector <- c(overallP, levelP)
return(pVector)
}
# create vector of new predictions corresponding to length of old prediction
switchFactor3 <- function(x) {
predictionOriginal <- unique(x)
if(predictionOriginal == "negative") {predictionNew <- "neutral"}
if(predictionOriginal == "positive") {predictionNew <- "neutral"}
if(predictionOriginal == "neutral")
{predictionNew <- sample(c("negative", "positive"), 1)}
predictionVector <- rep(predictionNew, length(x))
return(predictionVector)}
###############################
tsNames <- unique(dat[dat$Prediction != "none", ]$subSiteID)
tsNames <- unique(dat$subSiteID)
tsNames
tsN <- length(tsNames); tsN
switcharoo <- function(dat, newPredictions) {
randSample <- sample(tsNames, newPredictions)
# create subset to change
randChange <- dat[dat$subSiteID %in% randSample, ]
# create subset to keep
randKeep <- dat[!dat$subSiteID %in% randSample, ]
# get list of new predictions
predictionList <- tapply(X = randChange$PredictionOld,
INDEX = randChange$subSiteID, FUN = switchFactor3)
#need to change from list to a vector/data frame
predictionNew <- factor(matrix(unlist(predictionList)))
# create new changed subset of data
randChange2 <- randChange
randChange2$PredictionOld <- predictionNew
# create the new data frame
newDF <- rbind(randKeep,  randChange2)
# run the model and get the pValue
getTrtP(newDF)
}
predictionChanges <- c(1:13)
predictionChanges
AllReps <- predictionChanges
N <- length(AllReps); N
pValsList <- vector("list", length = N)
pValsList
names(pValsList) <- factor(predictionChanges)
str(pValsList)
pValsN <- 10 # number of times to replicate
switcharoo(dat, 4)
